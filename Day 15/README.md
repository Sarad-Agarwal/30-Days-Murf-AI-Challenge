# ğŸ™ï¸ AI Voice Agent â€” 30 Days of AI Voice Agents Challenge

An interactive AI-powered voice assistant that listens to user speech, transcribes it, generates an intelligent response using Google Gemini, and speaks back the answer using Murf AI.  
Built with **FastAPI** backend, **vanilla JS + HTML/CSS** frontend, and integrated with **AssemblyAI**, **Murf AI**, and **Google Gemini** APIs.

---

## ğŸš€ Features
- **ğŸ¤ Voice Input** â€” Record audio from your browser.
- **ğŸ“ Speech-to-Text (STT)** â€” Accurate transcription using AssemblyAI.
- **ğŸ¤– AI Responses** â€” Google Gemini generates natural conversational replies.
- **ğŸ—£ï¸ Text-to-Speech (TTS)** â€” Murf AI turns responses into realistic speech.
- **ğŸ’¬ Chat History** â€” Maintains conversation state per session.
- **âš ï¸ Error Handling** â€” Graceful fallbacks with both text and audio output.
- **ğŸŒ Cross-Origin Support** â€” Works seamlessly with any frontend.

---

## ğŸ› ï¸ Tech Stack
### Backend
- **FastAPI** â€” Lightweight, fast Python web framework.
- **Python-dotenv** â€” Manage API keys securely.
- **Requests** â€” API calls to third-party services.
- **Google Generative AI SDK** â€” For Gemini responses.

### Frontend
- HTML, CSS, JavaScript
- Interactive microphone animations
- Audio waveform visualizations

---

## ğŸ—ï¸ Project Structure
```

project-root/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py               # FastAPI entry point
â”‚   â”œâ”€â”€ models/                # Pydantic schemas
â”‚   â”œâ”€â”€ services/              # API integrations (STT, TTS, Gemini)
â”‚   â”œâ”€â”€ utils/                  # Helper functions
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env.example
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ app.js
â”‚   â”œâ”€â”€ style.css
â”‚
â””â”€â”€ README.md

````

---

## âš™ï¸ Environment Variables
Create a `.env` file in the `backend/` folder with:

```bash
ASSEMBLYAI_API_KEY=your_assemblyai_api_key
MURF_API_KEY=your_murf_api_key
GEMINI_API_KEY=your_gemini_api_key
````

You can also check `.env.example` for the format.

---

## â–¶ï¸ Running Locally

### 1ï¸âƒ£ Clone the repo

```bash
git clone https://github.com/your-username/ai-voice-agent.git
cd ai-voice-agent
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r backend/requirements.txt
```

### 3ï¸âƒ£ Set environment variables

Create `.env` inside `backend/` and add your API keys.

### 4ï¸âƒ£ Start the backend

```bash
uvicorn backend.main:app --reload
```

### 5ï¸âƒ£ Open frontend

Just open `frontend/index.html` in your browser, or serve it with a simple HTTP server:

```bash
cd frontend
python -m http.server 5500
```

---

## ğŸ“¡ API Endpoints

### `POST /agent/chat/{session_id}`

* **Description:** Accepts an audio file, transcribes it, gets AI response, and returns both text and audio URL.
* **Request:** Multipart/form-data with `file` parameter.
* **Response:**

```json
{
  "transcription": "...",
  "llmResponse": "...",
  "audioUrl": "...",
  "chatHistory": [...]
}
```

---

## ğŸ† Credits

* [AssemblyAI](https://www.assemblyai.com/) â€” Speech-to-Text
* [Murf AI](https://murf.ai/) â€” Text-to-Speech
* [Google Gemini](https://deepmind.google/) â€” AI responses

---

## ğŸ“œ License

MIT License Â© 2025 Sarad Agarwal


```
